{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf88b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "import torchmetrics\n",
    "from torchinfo import summary\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Internal libs\n",
    "os.chdir(\"../scripts\")  # WARNING: changing dir every time cell is called\n",
    "import data, engine, utils\n",
    "from constants import *\n",
    "os.chdir(\"../notebooks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93195adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.init()\n",
    "    torch.cuda.empty_cache()\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# For M1 Mac\n",
    "# if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "#     device = \"mps\"\n",
    "# else:\n",
    "#     device = \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31b9eb48-63ba-4061-af59-ad93316ae5aa",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0b48ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Data ------------------\n",
    "image_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "mask_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "(\n",
    "    train_dataloader,\n",
    "    dev_dataloader,\n",
    "    test_dataloader,\n",
    "    class_names,\n",
    ") = data.create_dataloaders(\n",
    "    train_dir=Path(f\"../{TRAIN_DIR}\"),\n",
    "    dev_dir=Path(f\"../{DEV_DIR}\"),\n",
    "    test_dir=Path(f\"../{TEST_DIR}\"),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    image_transform=image_transform,\n",
    "    mask_transform=mask_transform,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "11f5a1eb-db7f-49a3-9e35-1bde21d46de7",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e96d0a-c31e-4149-9ae9-d2a277beaa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import OrderedDict\n",
    "\n",
    "def my_load_state_dict(model: nn.Module, input_state_dict: OrderedDict):\n",
    "    \"\"\"loads input_state_dict into given model in place\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): model who's state_dict to update\n",
    "        input_state_dict (OrderedDict): will update model's curret state_dict\n",
    "    \"\"\"\n",
    "    own_state = model.state_dict()\n",
    "    for name, param in input_state_dict.items():\n",
    "        if name not in own_state:\n",
    "            continue\n",
    "        if isinstance(param, nn.Parameter):\n",
    "            # backwards compatibility for serialized parameters\n",
    "            param = param.data\n",
    "        own_state[name].copy_(param)\n",
    "\n",
    "\n",
    "def load_model(model_name: str, device: torch.device) -> nn.Module:\n",
    "    \"\"\"loads a model with state_dict from ./models/{model_name}/{model_name}.pth\"\"\"\n",
    "    # ------------------ Model ------------------\n",
    "    # instantiate DeepLabV3 model\n",
    "    model = torchvision.models.segmentation.deeplabv3_resnet50().to(device)\n",
    "\n",
    "    # modify classifier layer for desired number of classes\n",
    "    model.classifier = DeepLabHead(in_channels=2048, num_classes=NUM_CLASSES)\n",
    "\n",
    "    new_state_dict_path = Path(f\"../models/{model_name}/{model_name}.pth\")\n",
    "    new_state_dict = torch.load(new_state_dict_path, map_location=device)\n",
    "    my_load_state_dict(model, new_state_dict)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eca89502-8bd9-464d-9087-0b499fa9b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Universal Resnet50 23_06_04\"\n",
    "\n",
    "model = load_model(MODEL_NAME, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77bc0995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==================================================================================================================================\n",
       "Layer (type (var_name))                            Input Shape          Output Shape         Param #              Trainable\n",
       "==================================================================================================================================\n",
       "DeepLabV3 (DeepLabV3)                              [2, 3, 1024, 1024]   [2, 2, 1024, 1024]   --                   True\n",
       "├─IntermediateLayerGetter (backbone)               [2, 3, 1024, 1024]   [2, 2048, 128, 128]  --                   True\n",
       "│    └─Conv2d (conv1)                              [2, 3, 1024, 1024]   [2, 64, 512, 512]    9,408                True\n",
       "│    └─BatchNorm2d (bn1)                           [2, 64, 512, 512]    [2, 64, 512, 512]    128                  True\n",
       "│    └─ReLU (relu)                                 [2, 64, 512, 512]    [2, 64, 512, 512]    --                   --\n",
       "│    └─MaxPool2d (maxpool)                         [2, 64, 512, 512]    [2, 64, 256, 256]    --                   --\n",
       "│    └─Sequential (layer1)                         [2, 64, 256, 256]    [2, 256, 256, 256]   --                   True\n",
       "│    │    └─Bottleneck (0)                         [2, 64, 256, 256]    [2, 256, 256, 256]   75,008               True\n",
       "│    │    └─Bottleneck (1)                         [2, 256, 256, 256]   [2, 256, 256, 256]   70,400               True\n",
       "│    │    └─Bottleneck (2)                         [2, 256, 256, 256]   [2, 256, 256, 256]   70,400               True\n",
       "│    └─Sequential (layer2)                         [2, 256, 256, 256]   [2, 512, 128, 128]   --                   True\n",
       "│    │    └─Bottleneck (0)                         [2, 256, 256, 256]   [2, 512, 128, 128]   379,392              True\n",
       "│    │    └─Bottleneck (1)                         [2, 512, 128, 128]   [2, 512, 128, 128]   280,064              True\n",
       "│    │    └─Bottleneck (2)                         [2, 512, 128, 128]   [2, 512, 128, 128]   280,064              True\n",
       "│    │    └─Bottleneck (3)                         [2, 512, 128, 128]   [2, 512, 128, 128]   280,064              True\n",
       "│    └─Sequential (layer3)                         [2, 512, 128, 128]   [2, 1024, 128, 128]  --                   True\n",
       "│    │    └─Bottleneck (0)                         [2, 512, 128, 128]   [2, 1024, 128, 128]  1,512,448            True\n",
       "│    │    └─Bottleneck (1)                         [2, 1024, 128, 128]  [2, 1024, 128, 128]  1,117,184            True\n",
       "│    │    └─Bottleneck (2)                         [2, 1024, 128, 128]  [2, 1024, 128, 128]  1,117,184            True\n",
       "│    │    └─Bottleneck (3)                         [2, 1024, 128, 128]  [2, 1024, 128, 128]  1,117,184            True\n",
       "│    │    └─Bottleneck (4)                         [2, 1024, 128, 128]  [2, 1024, 128, 128]  1,117,184            True\n",
       "│    │    └─Bottleneck (5)                         [2, 1024, 128, 128]  [2, 1024, 128, 128]  1,117,184            True\n",
       "│    └─Sequential (layer4)                         [2, 1024, 128, 128]  [2, 2048, 128, 128]  --                   True\n",
       "│    │    └─Bottleneck (0)                         [2, 1024, 128, 128]  [2, 2048, 128, 128]  6,039,552            True\n",
       "│    │    └─Bottleneck (1)                         [2, 2048, 128, 128]  [2, 2048, 128, 128]  4,462,592            True\n",
       "│    │    └─Bottleneck (2)                         [2, 2048, 128, 128]  [2, 2048, 128, 128]  4,462,592            True\n",
       "├─DeepLabHead (classifier)                         [2, 2048, 128, 128]  [2, 2, 128, 128]     --                   True\n",
       "│    └─ASPP (0)                                    [2, 2048, 128, 128]  [2, 256, 128, 128]   --                   True\n",
       "│    │    └─ModuleList (convs)                     --                   --                   15,206,912           True\n",
       "│    │    └─Sequential (project)                   [2, 1280, 128, 128]  [2, 256, 128, 128]   328,192              True\n",
       "│    └─Conv2d (1)                                  [2, 256, 128, 128]   [2, 256, 128, 128]   589,824              True\n",
       "│    └─BatchNorm2d (2)                             [2, 256, 128, 128]   [2, 256, 128, 128]   512                  True\n",
       "│    └─ReLU (3)                                    [2, 256, 128, 128]   [2, 256, 128, 128]   --                   --\n",
       "│    └─Conv2d (4)                                  [2, 256, 128, 128]   [2, 2, 128, 128]     514                  True\n",
       "==================================================================================================================================\n",
       "Total params: 39,633,986\n",
       "Trainable params: 39,633,986\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 1.31\n",
       "==================================================================================================================================\n",
       "Input size (MB): 25.17\n",
       "Forward/backward pass size (MB): 17650.16\n",
       "Params size (MB): 158.54\n",
       "Estimated Total Size (MB): 17833.87\n",
       "=================================================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(\n",
    "    model=model, \n",
    "    input_size=(2, 3, 1024, 1024), \n",
    "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"], \n",
    "    col_width=20, \n",
    "    row_settings=[\"var_names\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
